{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203e7f71",
   "metadata": {},
   "source": [
    "### AI Research Agent prototype\n",
    "\n",
    "Features:\n",
    "1. User enters query/ topic of research\n",
    "2. The agent plans the flow, research -> reflect on findings -> summarize findings\n",
    "3. User gets a summary with citations of papers used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8021ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List, Dict\n",
    "\n",
    "\n",
    "# we need states for:\n",
    "# user query\n",
    "# results\n",
    "class AgentState(TypedDict):\n",
    "    query: str # the user query\n",
    "    original_plan: Dict[str, str] # entire plan returned by the planner, with rationale and reflection\n",
    "    plan: List[Dict] # \n",
    "    results: Dict\n",
    "    reflection: bool\n",
    "    reflection_notes: str\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8e57c",
   "metadata": {},
   "source": [
    "Now that we have defined the state, we create our nodes.\n",
    "First node is the planner node. We also need an llm to generate the execution plan, so first we define our llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677beb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Execution Plan**\n",
      "\n",
      "**Step 1: Foundational Models and Transformer Architecture**\n",
      "\n",
      "1.  **Purpose**: To identify the key foundational architectures preceding LLMs and the introduction of the Transformer architecture, which revolutionized the field.\n",
      "2.  **Query Parameters**:\n",
      "    *   **Search Tool**: arxiv\n",
      "    *   **Search Terms**: \"Transformer architecture\", \"Attention Is All You Need\", \"RNN LSTM natural language processing\"\n",
      "    *   **Additional Focus**: neural networks, sequence-to-sequence, machine translation\n",
      "3.  **Rationale**: \"Attention Is All You Need\" is the seminal paper for Transformers. Searching for earlier architectures like RNNs and LSTMs will provide context on what Transformers replaced or improved upon. arXiv is ideal for foundational research papers.\n",
      "\n",
      "**Step 2: Early LLMs and Scaling**\n",
      "\n",
      "1.  **Purpose**: To identify the first significant LLMs built upon the Transformer architecture and understand the initial phases of scaling and their capabilities.\n",
      "2.  **Query Parameters**:\n",
      "    *   **Search Tool**: arxiv\n",
      "    *   **Search Terms**: \"GPT-1\", \"BERT\", \"T5\", \"GPT-2\", \"GPT-3\"\n",
      "    *   **Additional Focus**: pre-training, language modeling, natural language understanding, generative models\n",
      "3.  **Rationale**: These models represent major milestones in LLM evolution, demonstrating the power of pre-training and scaling. arXiv will provide direct access to their original research papers detailing their architectures and contributions.\n",
      "\n",
      "**Step 3: Instruction Tuning, Alignment, and Recent Advancements**\n",
      "\n",
      "1.  **Purpose**: To understand the evolution towards instruction-following models, the role of alignment, and more recent trends like multimodal LLMs and open-source contributions.\n",
      "2.  **Query Parameters**:\n",
      "    *   **Search Tool**: web search\n",
      "    *   **Search Terms**: \"evolution of LLMs timeline\", \"ChatGPT InstructGPT alignment\", \"multimodal LLMs\", \"open source LLMs\"\n",
      "    *   **Additional Focus**: fine-tuning, reinforcement learning from human feedback (RLHF), large language models\n",
      "3.  **Rationale**: Web search is better for broader overviews, timelines, and understanding the impact and adoption of models like ChatGPT, which are often discussed in tech news and industry reports. It also helps capture the latest trends that might not yet have seminal arXiv papers.\n",
      "\n",
      "---\n",
      "\n",
      "**Self-Reflection**\n",
      "\n",
      "**Purpose**: To evaluate the gathered information for completeness and accuracy regarding the evolution of LLMs, ensuring all critical stages and breakthroughs are adequately covered for a comprehensive report.\n",
      "\n",
      "**Analysis Focus**:\n",
      "1.  **Timeline Accuracy**: Is there a clear, consistent timeline from early NLP models to current LLMs? Are key dates and model introductions correctly placed?\n",
      "2.  **Key Architectural Shifts**: Is the transition from RNN/LSTM to Transformer, and subsequent architectural refinements within Transformers, well-documented?\n",
      "3.  **Major Model Contributions**: Are the specific contributions of models like BERT, GPT-1/2/3, T5, and ChatGPT clearly identified (e.g., pre-training, scaling, instruction following, alignment)?\n",
      "4.  **Impact and Significance**: Is the broader impact of these developments (e.g., on NLP tasks, AI accessibility) sufficiently explained?\n",
      "5.  **Gaps**: Are there any missing eras, influential models, or significant conceptual breakthroughs that haven't been adequately covered?\n",
      "\n",
      "**Rationale**: A comprehensive report requires not just a list of models but an understanding of the *why* and *how* behind their evolution. This reflection ensures that the narrative flow is logical, the technical details are accurate, and the report addresses the \"evolution\" aspect thoroughly, rather than just being a catalog of models. If gaps are identified, further targeted searches (e.g., for specific missing models or concepts like \"scaling laws\" or \"RLHF\" if not fully covered) would be necessary.\n"
     ]
    }
   ],
   "source": [
    "# Test the planner prompt\n",
    "system_prompt = \"\"\" \n",
    "You are an expert research agent. \n",
    "You have access to an arxiv search and a web search tool. \n",
    "Given a user query, create an execution plan mapping the steps needed to get the desired result for the user.\n",
    "The plan should be detailed, with each step of the plan having the following:\n",
    "    1. Purpose: why is this step included in the execution plan\n",
    "    2. Query parameters: Only for the search tools\n",
    "    - search terms: exact terms to search for in the arxiv search_query or web search\n",
    "    - additional focus: any keywords that might help us to refine the search\n",
    "    3. Rationale: The rationale behind these search/ plan parameters. \n",
    "The plan should additionally follow a self reflection step, \n",
    "where it goes over the output generated from the search results\n",
    "to determine whether the data that we have is enough or more information is needed to make an informed decision\n",
    "The self reflection step should also be detailed with the following:\n",
    "    1. Purpose\n",
    "    2. Analysis focus\n",
    "    3. Rationale\n",
    "Limit your response to 500 words\n",
    "\n",
    "User query: \n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(system_prompt + \" write a report on evolution of LLMs\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ebe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"plan\": [\n",
      "    {\n",
      "      \"tool\": \"arxiv_search\",\n",
      "      \"purpose\": \"To find broad survey papers or comprehensive reviews that compare various image generation models at a high level, providing an initial overview.\",\n",
      "      \"query\": {\n",
      "        \"search_terms\": [\"image generation models comparison\", \"generative models survey\"],\n",
      "        \"additional_focus\": [\"review\", \"benchmark\", \"evaluation\", \"performance\"]\n",
      "      },\n",
      "      \"rationale\": \"These search terms are chosen to directly target papers that perform a comparative analysis across different types of image generation models, such as GANs, VAEs, and Diffusion Models. 'Survey', 'benchmark', 'evaluation', and 'performance' are added to narrow down to papers specifically focused on comparison and assessment.\"\n",
      "    },\n",
      "    {\n",
      "      \"tool\": \"arxiv_search\",\n",
      "      \"purpose\": \"To find comparisons specifically focused on Generative Adversarial Networks (GANs) and their variants, as they were a dominant paradigm for a significant period.\",\n",
      "      \"query\": {\n",
      "        \"search_terms\": [\"generative adversarial networks comparison\", \"GANs review\"],\n",
      "        \"additional_focus\": [\"FID\", \"Inception Score\", \"image quality\", \"training stability\", \"architectures\"]\n",
      "      },\n",
      "      \"rationale\": \"Focusing on 'generative adversarial networks comparison' and 'GANs review' helps identify papers detailing the evolution, strengths, and weaknesses of GANs. 'FID', 'Inception Score', 'image quality', 'training stability', and 'architectures' are key metrics and aspects often discussed in GAN comparisons.\"\n",
      "    },\n",
      "    {\n",
      "      \"tool\": \"arxiv_search\",\n",
      "      \"purpose\": \"To find comparisons specifically focused on Diffusion Models, which are currently state-of-the-art in many image generation tasks.\",\n",
      "      \"query\": {\n",
      "        \"search_terms\": [\"diffusion models comparison\", \"diffusion models review\"],\n",
      "        \"additional_focus\": [\"FID\", \"image quality\", \"sampling speed\", \"computational cost\", \"text-to-image\", \"conditional generation\"]\n",
      "      },\n",
      "      \"rationale\": \"This step targets the most recent advancements in image generation. 'Diffusion models comparison' and 'diffusion models review' are direct. 'FID', 'image quality', 'sampling speed', 'computational cost', 'text-to-image', and 'conditional generation' are critical aspects for evaluating and comparing diffusion models.\"\n",
      "    },\n",
      "    {\n",
      "      \"tool\": \"arxiv_search\",\n",
      "      \"purpose\": \"To find comparisons involving Variational Autoencoders (VAEs) and Autoregressive Models, which are foundational and still relevant in certain contexts of image generation.\",\n",
      "      \"query\": {\n",
      "        \"search_terms\": [\"variational autoencoders comparison\", \"autoregressive models image generation review\"],\n",
      "        \"additional_focus\": [\"reconstruction quality\", \"likelihood\", \"diversity\", \"latent space\"]\n",
      "      },\n",
      "      \"rationale\": \"While not always leading in raw image quality, VAEs and Autoregressive models provide different trade-offs and are important for a comprehensive understanding. 'Reconstruction quality', 'likelihood', 'diversity', and 'latent space' are key evaluation criteria for these model types.\"\n",
      "    }\n",
      "  ],\n",
      "  \"reflection\": {\n",
      "    \"purpose\": \"To synthesize the information gathered from the arXiv searches into a comprehensive comparison of different image generation models.\",\n",
      "    \"analysis_focus\": [\n",
      "      \"Key architectural differences between models (e.g., GANs, VAEs, Diffusion Models, Autoregressive Models)\",\n",
      "      \"Quantitative performance metrics and their typical ranges (e.g., FID, Inception Score, PSNR, LPIPS)\",\n",
      "      \"Qualitative assessment of generated image quality, diversity, and coherence\",\n",
      "      \"Strengths and weaknesses of each model type (e.g., training stability, sampling speed, mode collapse, computational cost)\",\n",
      "      \"Specific applications or scenarios where each model type excels\",\n",
      "      \"Historical evolution and current trends in image generation models\"\n",
      "    ],\n",
      "    \"rationale\": \"This reflection is crucial to move beyond simply listing papers to actually extracting and structuring the comparative information requested by the user. Focusing on these aspects ensures a thorough and insightful comparison.\"\n",
      "  }\n",
      "} <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert research agent planner.\n",
    "\n",
    "You have access to the following tools:\n",
    "- arxiv_search: for academic papers\n",
    "- web_search: for general sources\n",
    "\n",
    "Your job is to take a user query and return a structured execution plan in STRICT JSON format.\n",
    "Do not include any text outside of the JSON. Do not explain your reasoning in prose.\n",
    "\n",
    "The JSON must follow this schema exactly:\n",
    "\n",
    "{\n",
    "  \"plan\": [\n",
    "    {\n",
    "      \"tool\": \"<tool_name>\",\n",
    "      \"purpose\": \"<why this step is included>\",\n",
    "      \"query\": {\n",
    "        \"search_terms\": [\"<list of exact search terms>\"],\n",
    "        \"additional_focus\": [\"<list of optional focus keywords>\"]\n",
    "      },\n",
    "      \"rationale\": \"<why these parameters were chosen>\"\n",
    "    }\n",
    "  ],\n",
    "  \"reflection\": {\n",
    "    \"purpose\": \"<why reflection is needed>\",\n",
    "    \"analysis_focus\": [\"<list of aspects to check>\"],\n",
    "    \"rationale\": \"<why this reflection matters>\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Return only valid JSON. Do not include markdown formatting, explanations, or extra text.\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(system_prompt + \"\\nUser query: comparison of different image generation models\")\n",
    "print(response.content, type(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b668b5",
   "metadata": {},
   "source": [
    "Now that we have a sample prompt and response to generate a plan, let's add that to a planner node.\n",
    "\n",
    "* The planner node will have a system prompt and a user query from the state. \n",
    "* The LLM returns a structured JSON object with the detailed execution plan.\n",
    "* We parse that JSON and update the state variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37818038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def planner(state: AgentState) -> AgentState:\n",
    "    \"\"\" Generate a detailed execution plan for the user query \"\"\"\n",
    "\n",
    "    # First check if there are any previous reflections in reflection_notes\n",
    "    # If yes, generate a new plan/ or additional search parameters\n",
    "    # If no, this is the first run, run normally\n",
    "    # So we probably also need to manage the original_plan somehow to accomodate the new plan after reflection, if any\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert research agent planner.\n",
    "\n",
    "    You have access to the following tools:\n",
    "    - arxiv_search: for academic papers\n",
    "\n",
    "    Your job is to take a user query and return a structured execution plan in STRICT JSON format.\n",
    "    Do not include any text outside of the JSON. Do not explain your reasoning in prose.\n",
    "\n",
    "    The JSON must follow this schema exactly:\n",
    "\n",
    "    {\n",
    "    \"plan\": [\n",
    "        {\n",
    "        \"tool\": \"<tool_name>\",\n",
    "        \"purpose\": \"<why this step is included>\",\n",
    "        \"query\": {\n",
    "            \"search_terms\": [\"<list of exact search terms>\"],\n",
    "            \"additional_focus\": [\"<list of optional focus keywords>\"]\n",
    "        },\n",
    "        \"rationale\": \"<why these parameters were chosen>\"\n",
    "        }\n",
    "    ],\n",
    "    \"reflection\": {\n",
    "        \"purpose\": \"<why reflection is needed>\",\n",
    "        \"analysis_focus\": [\"<list of aspects to check>\"],\n",
    "        \"rationale\": \"<why this reflection matters>\"\n",
    "    }\n",
    "    }\n",
    "\n",
    "    Return  ONLY VALID JSON. Do not include markdown formatting (NO ```json ... ```), explanations, or extra text.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=state[\"query\"])\n",
    "    ]\n",
    "\n",
    "    # response = llm.invoke(system_prompt + state[\"query\"])\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    response_json = response.content[7:-3]\n",
    "    try:\n",
    "        state[\"original_plan\"] = json.loads(response_json) # Load plan JSON as python dictionary\n",
    "    except Exception as e:\n",
    "        print(response)\n",
    "        print(e)\n",
    "    \n",
    "    response_dict = json.loads(response_json) # Convert JSON string to python dictionary\n",
    "\n",
    "    state[\"plan\"] = response_dict[\"plan\"]\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c15f2",
   "metadata": {},
   "source": [
    "The planner node is ready now, let's start defining our tools. Currently we have two tools:\n",
    "\n",
    "1. arxiv search\n",
    "2. websearch (probably serpapi)\n",
    "\n",
    "Just defining the tool skeleton for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import feedparser\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from urllib.parse import quote\n",
    "\n",
    "@tool\n",
    "def search_arxiv(state: AgentState) -> list[dict[str:any]]:\n",
    "    \"\"\" given the current Agent State, search arxiv and return appropriate papers. \"\"\"\n",
    "    \n",
    "    # pass the search_terms and additional_terms to the llm\n",
    "    search_terms = state[\"plan\"][0][\"query\"][\"search_terms\"]\n",
    "    additional_focus = state[\"plan\"][0][\"query\"][\"additional_terms\"]\n",
    "\n",
    "    # make the llm generate appropriate arxiv search queries\n",
    "\n",
    "    query_expansion_prompt = f\"\"\"\n",
    "    You are an expert at constructing arxiv API queries. \n",
    "    Given the following search terms and additional focus terms, generate efficient arXiv API queries.\n",
    "\n",
    "    Requirements:\n",
    "    - Always include the exact search_terms verbatim.\n",
    "    - Incorporate additional_focus terms.\n",
    "    - Use arXiv field prefixes where appropriate:\n",
    "      - ti: for title\n",
    "      - abs: for abstract\n",
    "      - cat:cs.CL for computational linguistics\n",
    "    - Combine terms with AND/OR for precision.\n",
    "    - Return 2-3 queries max.\n",
    "\n",
    "    Return only a JSON list of objects. \n",
    "    Each object must have:\n",
    "    - \"search_query\": a valid arXiv API query string\n",
    "    - \"max_results\": an integer (default 5)\n",
    "\n",
    "    Return only valid JSON. Do not include markdown formatting, explanations, or extra text.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "       SystemMessage(content=query_expansion_prompt), \n",
    "       HumanMessage(content=f\"\\nSearch terms:{search_terms}\\nAdditional focus:{additional_focus}\")\n",
    "    ]\n",
    "\n",
    "    # queries = llm.invoke(query_expansion_prompt)\n",
    "\n",
    "    queries = llm.invoke(messages)\n",
    "    queries_json = queries.content[7:-3]\n",
    "\n",
    "    try:\n",
    "      queries_dict = json.loads(queries_json)\n",
    "    except Exception as e:\n",
    "      print(queries)\n",
    "      print(e)\n",
    "    \n",
    "    # use those queries to search the web for top results\n",
    "\n",
    "    base_url = 'http://export.arxiv.org/api/query?'\n",
    "    results = []\n",
    "    max_results = 5\n",
    "\n",
    "    # construct valid arxiv url for each search query returned by the LLM and get appropriate papers\n",
    "    for query in queries_dict:\n",
    "        search_query = quote(query[\"search_query\"])  # URL-encode\n",
    "        url = base_url + f\"search_query={search_query}&max_results={max_results}&sortBy=submittedDate&sortOrder=descending\"\n",
    "        # print(url)\n",
    "        feed = feedparser.parse(url)\n",
    "        results.append(feed.entries)\n",
    "\n",
    "    # consolidate all results somehow (not thought about it yet)\n",
    "    # for now, just as a list\n",
    "    # will use a vector store later\n",
    "\n",
    "    for i in range(len(results)):\n",
    "      for result in results[i]:\n",
    "          # print(result)\n",
    "          # print(\"Title:\", result.title)\n",
    "          # print(\"Authors:\", [author['name'] for author in result['authors']])\n",
    "          # print(\"Published:\", result['published'])\n",
    "          # print(\"Summary:\", result['summary'])\n",
    "          # print(\"Link:\", result['link'])\n",
    "          # print(\"\\n\")\n",
    "\n",
    "          result_dict = {\n",
    "            \"title\": result['title'],\n",
    "            \"published:\": result['published'],\n",
    "            \"summary:\": result['summary'],\n",
    "            \"arxiv_link:\": result['link'],\n",
    "            \"pdf_link\": result['links'][2]['href'] # or just /pdf instead of /obs in the arxiv link\n",
    "          }\n",
    "\n",
    "          state[\"results\"][\"arxiv\"].append((result_dict))\n",
    "\n",
    "    # finally, pop the current tool from plan (pop(0))\n",
    "    state[\"plan\"].pop(0)\n",
    "    \n",
    "    return state[\"results\"][\"arxiv\"]\n",
    "\n",
    "\n",
    "# Skipping web search for the initial MVP, will add later once the entire flow is working with arxiv\n",
    "@tool\n",
    "def search_web(search_terms: list[str], additional_focus: list[str]) -> list[dict[str:str]]:\n",
    "    \"\"\" given some search terms and additional focus terms,\n",
    "      search the web and retrieve results \"\"\"\n",
    "    \n",
    "    # pass the search_terms and additional_terms to the llm\n",
    "    # make the llm generate appropriate web search queries\n",
    "    # use those queries to search arxiv for top papers\n",
    "    # consolidate all papers somehow (not thought about it yet)\n",
    "    # finally, pop the current tool from plan (pop(0))\n",
    "    \n",
    "    return [{\"title\":\"...\", \"author\":\"...\", \"abstract\":\"...\"}]\n",
    "\n",
    "\n",
    "tools = [search_arxiv]\n",
    "tool_node = ToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23270a20",
   "metadata": {},
   "source": [
    "Now, we have defined our tools. Let's add the router node that will check if any tools are yet to be called and routes actions accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def router(state: AgentState):\n",
    "    \"\"\" To check if any more tool calls are left and routing to the appropriate tools \"\"\"\n",
    "\n",
    "    # if plan is empty, go to the reflection step\n",
    "    if not state[\"plan\"]:\n",
    "        return \"reflection\"\n",
    "    else:\n",
    "        return ToolInvocation(\n",
    "            tool=state[\"plan\"][0][\"tool\"],\n",
    "            tool_input=state\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b6d03f",
   "metadata": {},
   "source": [
    "Add a reflection node and a summarize node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f9e0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection(state: AgentState):\n",
    "    \"\"\" reflect on the current findings \"\"\"\n",
    "\n",
    "    # This will again be a conditional edge, which will either route to summarize or back to plan\n",
    "    # Implement reflection/ EVAL logic\n",
    "    # If reflection sufficient, route to the summarize state\n",
    "    # Else, store reflection_notes, go back to the planner with current reflection, generate and execute new plan\n",
    "\n",
    "    original_reflection = json.dumps(state[\"original_plan\"][\"reflection\"])\n",
    "    papers_json = json.dumps(state[\"results\"][\"arxiv\"])\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a research agent tasked with evaluating whether the collected papers are sufficient to fulfill the current research plan.\n",
    "\n",
    "    Instructions:\n",
    "    - Read the research plan's reflection goal carefully.\n",
    "    - Review the list of retrieved papers (title, summary, link).\n",
    "    - Decide whether these papers are sufficient to proceed to summarization.\n",
    "    - If sufficient, explain why.\n",
    "    - If not, explain what is missing and suggest new directions to search.\n",
    "\n",
    "    Return only valid JSON in the following format:\n",
    "    {\n",
    "    \"sufficient\": true or false,\n",
    "    \"notes\": \"Your reasoning and suggestions\"\n",
    "    }\n",
    "    Return only valid JSON. Do not include markdown formatting, explanations, or extra text.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=\"\\nplanned reflection:\\n\" + original_reflection + \"\\nCollecte papers in JSON format:\\n\"+papers_json)\n",
    "    ]\n",
    "\n",
    "    # response = llm.invoke(system_prompt + \"\\nplanned reflection:\\n\" + original_reflection + \"\\nCollecte papers in JSON format:\\n\"+papers_json)\n",
    "    response = llm.invoke(messages)\n",
    "    response_json = response.content[7:-3]\n",
    "\n",
    "    try:\n",
    "        response_dict = json.loads(response_json)\n",
    "    except Exception as e:\n",
    "        print(response)\n",
    "        print(e)\n",
    "\n",
    "    state[\"reflection\"] = response_dict[\"sufficient\"]\n",
    "    state[\"reflection_notes\"] = response_dict[\"notes\"]\n",
    "\n",
    "    if state[\"reflection\"]:\n",
    "        return \"summarize\"\n",
    "    else:\n",
    "        return \"plan\"\n",
    "\n",
    "def summarize(state: AgentState) -> AgentState:\n",
    "    \"\"\" summarize the findings \"\"\"\n",
    "\n",
    "    # Summarize the findings and store them in the state[\"summary\"]\n",
    "\n",
    "    papers = json.dumps(state[\"results\"][\"arxiv\"])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a research agent tasked with summarizing the findings from a set of retrieved papers.\n",
    "\n",
    "    Instructions:\n",
    "    - Read the titles, summaries, and links of the papers.\n",
    "    - Synthesize the key insights relevant to the original research goal.\n",
    "    - Reference paper titles and include links where appropriate.\n",
    "    - Write a coherent, readable summary suitable for a research report.\n",
    "    \"\"\"\n",
    "\n",
    "    # User Query:\n",
    "    # {state[\"query\"]}\n",
    "\n",
    "    # Papers:\n",
    "    # {papers}\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=prompt),\n",
    "        HumanMessage(content=f\"User query: {state[\"query\"]}\\nPapers: {papers}\")\n",
    "    ]\n",
    "\n",
    "    summary = llm.invoke(messages)\n",
    "    state[\"final_summary\"] = summary\n",
    "\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ed38e",
   "metadata": {},
   "source": [
    "Now, create the graph. This is still just a skeleton graph to inspect the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbd38785",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"planner\", planner)\n",
    "graph.add_node(\"router\", lambda state:state)\n",
    "graph.add_edge(\"planner\", \"router\")\n",
    "graph.add_node(\"reflection\", lambda state:state)\n",
    "graph.add_node(\"summarize\", summarize)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "graph.set_entry_point(\"planner\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    router,\n",
    "    {\n",
    "        \"use_tool\": \"tools\",\n",
    "        \"reflection\": \"reflection\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"tools\", \"router\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"reflection\",\n",
    "    reflection,\n",
    "    {\n",
    "        \"summarize\":\"summarize\",\n",
    "        \"plan\": \"planner\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"summarize\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd29e3",
   "metadata": {},
   "source": [
    "Visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ac1c69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dafe9331",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No message found in input",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# class AgentState(TypedDict):\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#     query: str # the user query\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     original_plan: Dict[str, str] # entire plan returned by the planner, with rationale and reflection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#     reflection_notes: str\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#     summary: str\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatest advancements in image generation models\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:346\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, store)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_func\u001b[39m(\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    341\u001b[39m     \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mlist\u001b[39m[AnyMessage] | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | BaseModel,\n\u001b[32m   (...)\u001b[39m\u001b[32m    344\u001b[39m     store: BaseStore | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    345\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     tool_calls, input_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m     config_list = get_config_list(config, \u001b[38;5;28mlen\u001b[39m(tool_calls))\n\u001b[32m    348\u001b[39m     input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:544\u001b[39m, in \u001b[36mToolNode._parse_input\u001b[39m\u001b[34m(self, input, store)\u001b[39m\n\u001b[32m    542\u001b[39m     input_type = \u001b[33m\"\u001b[39m\u001b[33mdict\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo message found in input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    547\u001b[39m     latest_ai_message = \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m    548\u001b[39m         m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(messages) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, AIMessage)\n\u001b[32m    549\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No message found in input",
      "During task with name 'tools' and id 'cbb763e0-da95-f3a6-eed9-b1beab76e0e9'"
     ]
    }
   ],
   "source": [
    "# class AgentState(TypedDict):\n",
    "#     query: str # the user query\n",
    "#     original_plan: Dict[str, str] # entire plan returned by the planner, with rationale and reflection\n",
    "#     plan: List[Dict] # \n",
    "#     results: Dict\n",
    "#     reflection: bool\n",
    "#     reflection_notes: str\n",
    "#     summary: str\n",
    "\n",
    "app.invoke({\"query\":\"latest advancements in image generation models\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a73a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
